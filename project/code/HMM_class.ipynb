{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aac5087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hmm_conf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hmm_conf.py\n",
    "# Config file\n",
    "import numpy as np\n",
    "\n",
    "states = 2 #redundant \n",
    "state_names=[\"Fair\", \"Loaded\"]\n",
    "\n",
    "#Give matrix in the same order regarding states\n",
    "\n",
    "#NOTE must be in real space\n",
    "# The Viberti implementention will transform to log10 space on its own.\n",
    "\n",
    "initial_prob = [1.0/states, 1.0/states]\n",
    "\n",
    "transition_matrix = np.array([\n",
    "    [0.95,0.05],\n",
    "    [0.1, 0.9]\n",
    "])\n",
    "\n",
    "symbols = \"123456\"\n",
    "\n",
    "emission_probs = np.array([\n",
    "    [1.0/6, 1.0/6, 1.0/6, 1.0/6, 1.0/6, 1.0/6],\n",
    "    [1.0/10, 1.0/10, 1.0/10, 1.0/10, 1.0/10, 5.0/10]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572415e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hmmClass.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hmmClass.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class hmm_decoder():\n",
    "    \n",
    "    def __init__(self, sequence, outfile=None, verbose=False, state=0):\n",
    "               \n",
    "        \n",
    "        self.logged = False #Flag for whether probs are log transformed\n",
    "        #except:\n",
    "         #   print(\"Config file not probably configured\")\n",
    "         #   sys.exit\n",
    "        self.filename = outfile\n",
    "        self.verbose = verbose\n",
    "        self.set_sequence(sequence)\n",
    "    \n",
    "    def set_parameters(self,)\n",
    "    \n",
    "    def load_configfile(self):\n",
    "        from hmm_conf import states, transition_matrix, symbols, emission_probs, initial_prob, state_names\n",
    "        self.states = states\n",
    "        self.state_names = state_names\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.symbols = symbols\n",
    "        self.emission_probs = emission_probs\n",
    "        self.initial_prob = initial_prob\n",
    "        self.p_state = state\n",
    "    \n",
    "    def set_sequence(self, seq):\n",
    "        self.sequence = seq\n",
    "        self.encode_seq()\n",
    "    \n",
    "    def encode_seq(self):\n",
    "        if self.sequence is None:\n",
    "            raise Exception (\"No sequence set\")\n",
    "    \n",
    "        enc = [0] * len(self.sequence)\n",
    "\n",
    "        for i in range(len(self.sequence)):\n",
    "            enc[i] = self.symbols.find(self.sequence[i])\n",
    "\n",
    "        self.encoded_sequence = enc\n",
    "        \n",
    "    def log_probs(self):\n",
    "        self.logged = True\n",
    "        self.initial_prob = np.log10(self.initial_prob) \n",
    "        self.emission_probs  = np.log10(self.emission_probs)\n",
    "        self.transition_matrix = np.log10(self.transition_matrix)\n",
    "    \n",
    "    def pwr_probs(self):\n",
    "        self.logged = False\n",
    "        self.initial_prob = np.power(10, self.initial_prob) \n",
    "        self.emission_probs  = np.power(10, self.emission_probs)\n",
    "        self.transition_matrix = np.power(10, self.transition_matrix)\n",
    "    \n",
    "    def viterbi_init(self):\n",
    "        if not self.logged:\n",
    "            self.log_probs()\n",
    "        if not hasattr(self, \"encoded_sequence\"):\n",
    "            self.encode_seq()\n",
    "\n",
    "        delta = np.zeros(shape=(self.states, len(self.encoded_sequence)))\n",
    "\n",
    "        arrows = np.ndarray(shape=(self.states, len(self.encoded_sequence)), dtype=object)\n",
    "\n",
    "        # initial conditions\n",
    "        for i in range(0, self.states):\n",
    "\n",
    "            delta[i][0] = self.initial_prob[i]+self.emission_probs[i][self.encoded_sequence[0]] # Remember we work in log space \n",
    "\n",
    "            arrows[i][0] = 0\n",
    "\n",
    "        self.delta = delta\n",
    "        self.arrows = arrows\n",
    "    \n",
    "    def viterbi_calc_delta(self):\n",
    "        self.viterbi_init()\n",
    "        # main loop\n",
    "        for i in range(1, len(self.encoded_sequence)):\n",
    "\n",
    "            for j in range(0, self.states): #Current state j\n",
    "\n",
    "                max_arrow_prob = -np.inf # A very low negative number\n",
    "                max_arrow_prob_state = -1\n",
    "\n",
    "                for k in range(0, self.states): #Prior state k\n",
    "\n",
    "                    # arrow_prob is the probability of ending in the state j from the state k\n",
    "                    arrow_prob = self.delta[k][i-1] + self.transition_matrix[k,j] + self.emission_probs[j][self.encoded_sequence[i]] #\n",
    "\n",
    "                    if arrow_prob > max_arrow_prob: \n",
    "                        max_arrow_prob = arrow_prob #\n",
    "                        max_arrow_prob_state = k #\n",
    "\n",
    "                # store prob\n",
    "                self.delta[j][i] = max_arrow_prob\n",
    "\n",
    "                # store arrow\n",
    "                self.arrows[j][i] = max_arrow_prob_state\n",
    "                \n",
    "        if self.verbose: print(\"Delta Matrix: \"), print(self.delta)\n",
    "    \n",
    "    def viterbi_traceback(self):\n",
    "        if not hasattr(self, \"delta\"):\n",
    "            self.viterbi_calc_delta()\n",
    "        \n",
    "        if self.filename is None: \n",
    "            fh = None\n",
    "        else:\n",
    "            fh = open(self.filename , \"w\")\n",
    "        \n",
    "        path = []\n",
    "\n",
    "        max_state = np.argmax(self.delta[:, -1]) # Find the index of the max value in the last column of delta\n",
    "        max_value = self.delta[max_state, -1] # Find the max value in the last column of delta\n",
    "\n",
    "        print(\"log(Max_path):\", max_value, file=fh)\n",
    "\n",
    "        print(\"Seq: \", self.sequence, file=fh)\n",
    "\n",
    "        path.append(str(max_state))\n",
    "\n",
    "        old_state = max_state\n",
    "\n",
    "        for i in range(len(self.encoded_sequence)-2, -1, -1):\n",
    "\n",
    "            current_state = self.arrows[old_state][i+1]\n",
    "\n",
    "            path.append(str(current_state))\n",
    "\n",
    "            old_state = current_state \n",
    "\n",
    "        print(\"Path:\", \"\".join(reversed(path)), file=fh)\n",
    "        \n",
    "        if fh: fh.close()\n",
    "    \n",
    "    def forward_ini(self):\n",
    "        if self.logged:\n",
    "            self.log_probs()\n",
    "        if not hasattr(self, \"encoded_sequence\"):\n",
    "            self.encode_seq()\n",
    "\n",
    "        alpha = np.zeros(shape=(self.states, len(self.encoded_sequence)))\n",
    "\n",
    "        for i in range(0, self.states): \n",
    "\n",
    "            alpha[i][0] = self.initial_prob[i]*self.emission_probs[i][self.encoded_sequence[0]]\n",
    "\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def backward_ini(self):\n",
    "        if not hasattr(self, \"encoded_sequence\"):\n",
    "            self.encode_seq()\n",
    "       \n",
    "        beta = np.zeros(shape=(self.states, len(self.encoded_sequence)))\n",
    "\n",
    "        for i in range(0, self.states):\n",
    "\n",
    "            beta[i][-1] = 1\n",
    "\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward_run(self):\n",
    "        self.forward_ini()\n",
    "        alpha = self.alpha\n",
    "        \n",
    "        # main loop\n",
    "        for i in range(1, len(self.encoded_sequence)):\n",
    "\n",
    "            for j in range(0, self.states):\n",
    "                #Sum of probabilities for all states in the prior position\n",
    "                _sum = sum([alpha[k][i-1]* self.transition_matrix[k,j] for k in range(self.states)]) \n",
    "                # store prob\n",
    "                alpha[j][i] = self.emission_probs[j][self.encoded_sequence[i]] * _sum\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def backward_run(self):\n",
    "        self.backward_ini()\n",
    "            \n",
    "        for i in range(len(self.encoded_sequence)-2, -1, -1):\n",
    "\n",
    "            for j in range(0, self.states):\n",
    "\n",
    "                _sum = 0\n",
    "\n",
    "                for k in range(0, self.states):\n",
    "\n",
    "                    _sum += self.emission_probs[k][self.encoded_sequence[i+1]] * self.transition_matrix[j,k] * self.beta[k][i+1]\n",
    "\n",
    "                # store prob\n",
    "                self.beta[j][i] = _sum\n",
    "\n",
    "\n",
    "\n",
    "    def calc_posterior(self):\n",
    "        self.forward_run()\n",
    "        self.backward_run()\n",
    "            \n",
    "        p_state = self.p_state\n",
    "        \n",
    "        \n",
    "        posterior = np.zeros(shape=(len(self.encoded_sequence)), dtype=float)\n",
    "        \n",
    "\n",
    "        p_x = 0\n",
    "        for j in range(0, self.states):\n",
    "            p_x += self.alpha[j][-1]\n",
    "            \n",
    "        if self.filename is None: \n",
    "            fh = None\n",
    "        else:\n",
    "            fh = open(self.filename , \"w\")\n",
    "\n",
    "        print (\"Log(Px):\", np.log(p_x), file=fh)\n",
    "\n",
    "        for i in range(0, len(self.encoded_sequence)):\n",
    "\n",
    "            posterior[i] = (self.alpha[p_state][i]*self.beta[p_state][i])/p_x # p = (f_i * b_i)/p_x\n",
    "\n",
    "            print (\"Posterior\", i, self.sequence[i], self.encoded_sequence[i], np.log(self.alpha[p_state, i]), np.log(self.beta[p_state, i]), posterior[i], file=fh)\n",
    "        self.posterior = posterior\n",
    "    \n",
    "    def plot_posterior(self):\n",
    "        if not hasattr(self, \"posterior\"):\n",
    "            print(\"posterior missing: Calculating now\")\n",
    "            self.calc_posterior()\n",
    "        \n",
    "        plt.bar(x = [x for x in range(len(self.sequence))], \n",
    "                height = self.posterior,\n",
    "                tick_label = [x for x in self.sequence])\n",
    "\n",
    "        plt.xlabel(\"Sequence\")\n",
    "        plt.ylabel(f\"P(state = {self.state_names[self.p_state]})\")\n",
    "\n",
    "        plt.savefig(\"posterior.png\")\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e92d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hmm_BaumWelch():\n",
    "    \n",
    "    def __init__(seqeunce):\n",
    "        \n",
    "    \n",
    "    def forward_ini(self):\n",
    "        if self.logged:\n",
    "            self.log_probs()\n",
    "        if not hasattr(self, \"encoded_sequence\"):\n",
    "            self.encode_seq()\n",
    "\n",
    "        alpha = np.zeros(shape=(self.states, len(self.encoded_sequence)))\n",
    "\n",
    "        for i in range(0, self.states): \n",
    "\n",
    "            alpha[i][0] = self.initial_prob[i]*self.emission_probs[i][self.encoded_sequence[0]]\n",
    "\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def backward_ini(self):\n",
    "        if not hasattr(self, \"encoded_sequence\"):\n",
    "            self.encode_seq()\n",
    "       \n",
    "        beta = np.zeros(shape=(self.states, len(self.encoded_sequence)))\n",
    "\n",
    "        for i in range(0, self.states):\n",
    "\n",
    "            beta[i][-1] = 1\n",
    "\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward_run(self):\n",
    "        self.forward_ini()\n",
    "        alpha = self.alpha\n",
    "        \n",
    "        # main loop\n",
    "        for i in range(1, len(self.encoded_sequence)):\n",
    "\n",
    "            for j in range(0, self.states):\n",
    "                #Sum of probabilities for all states in the prior position\n",
    "                _sum = sum([alpha[k][i-1]* self.transition_matrix[k,j] for k in range(self.states)]) \n",
    "                # store prob\n",
    "                alpha[j][i] = self.emission_probs[j][self.encoded_sequence[i]] * _sum\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def backward_run(self):\n",
    "        self.backward_ini()\n",
    "            \n",
    "        for i in range(len(self.encoded_sequence)-2, -1, -1):\n",
    "\n",
    "            for j in range(0, self.states):\n",
    "\n",
    "                _sum = 0\n",
    "\n",
    "                for k in range(0, self.states):\n",
    "\n",
    "                    _sum += self.emission_probs[k][self.encoded_sequence[i+1]] * self.transition_matrix[j,k] * self.beta[k][i+1]\n",
    "\n",
    "                # store prob\n",
    "                self.beta[j][i] = _sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
